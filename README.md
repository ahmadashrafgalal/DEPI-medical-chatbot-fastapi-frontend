# ğŸ©º Medical Chatbot

**AI-Powered Medical Assistant using RAG, FAISS, Sentence Transformers, and Mistral**

![Application Screenshot](Img.png)

---

## ğŸ“Œ Overview

The **Medical RAG Chatbot** is an intelligent AI system designed to provide friendly, medically oriented responses using an advanced Retrieval-Augmented Generation (RAG) pipeline. It combines:

* **FAISS vector search** for fast similarity retrieval
* **SentenceTransformer embeddings**
* **Mistral-7B Instruct** for rewriting and generating answers
* **FastAPI backend**
* **HTML/Jinja2 frontend**

The system workflow:

1. Clean and normalize medical text
2. Expand medical abbreviations
3. Rewrite the user question using Mistral
4. Convert question to embeddings using MiniLM
5. Search similar Q&A using FAISS
6. Build a context-enriched prompt using retrieved data
7. Generate the final medical answer
8. Convert answer into a warm, friendly doctor-like tone

---

# ğŸ§  System Architecture

```
User
   â†“
Frontend (index.html)
   â†“
FastAPI Backend
   â†“
Mistral â†’ Rewrite Question
   â†“
SentenceTransformer â†’ Embedding
   â†“
FAISS â†’ Retrieve Similar Medical Q&A
   â†“
Prompt Builder
   â†“
Mistral â†’ Raw Answer Generation
   â†“
Mistral â†’ Conversational Doctor Tone
   â†“
Return Final Answer to User
```

---

# ğŸ“‚ Project Structure

```
DEPI-medical-chatbot-fastapi-frontend/
â”‚
â”œâ”€â”€ main.py                       # FastAPI application and endpoints
â”œâ”€â”€ last_api.py                   # RAG pipeline, embeddings, FAISS, Mistral logic
â”œâ”€â”€ HealthCareMagic-5k.json       # Medical Q&A dataset
â”œâ”€â”€ question_embeddings.npy        # Precomputed embedding vectors
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                # Web chat interface
â”‚
â”œâ”€â”€ Img.png                       # Application screenshot
â”œâ”€â”€ UI.png                        # UI design screenshot
â”œâ”€â”€ README.md                     # Documentation file
â””â”€â”€ .gitignore
```

---

# ğŸ§¬ Dataset

The project uses the **HealthCareMagic** dataset, containing real-world patient questions and doctor responses:

* `input` â†’ Patient question
* `output` â†’ Doctor answer

### Preprocessing includes:

* Lowercasing
* URL removal
* Number removal
* Stopword filtering
* Contraction expansion
* Lemmatization
* Medical abbreviation expansion (e.g., â€œBPâ€ â†’ â€œblood pressureâ€)
* Markdown cleanup

---

# ğŸ§¹ Preprocessing Pipeline

### Steps:

1. Remove URLs
2. Clean special characters
3. Remove digits
4. Remove stopwords
5. Normalize medical abbreviations
6. Lemmatize text
7. Clean markdown patterns
8. Expand contractions

This ensures optimized embeddings and better retrieval accuracy.

---

# ğŸ“Š Embedding & Vector Indexing

The system uses:

### **Embedding Model:**

`all-MiniLM-L6-v2` â€” optimized for semantic search

### **FAISS Index:**

`IndexFlatIP` using **Inner Product** similarity
All vectors are **L2-normalized** before indexing.

Process:

1. Encode all dataset questions
2. Normalize embeddings
3. Save to `question_embeddings.npy`
4. Build FAISS index
5. Search for top-k similar entries (`k = 3`)

---

# ğŸ¤– Mistral AI Integration

The chatbot uses three sequential inference steps:

### 1ï¸âƒ£ Rewrite the user input

* Makes unclear questions medically precise
* Improves retrieval accuracy

### 2ï¸âƒ£ Generate the final medical answer

* Uses retrieved FAISS context
* Produces accurate medical explanations

### 3ï¸âƒ£ Apply a conversational doctor tone

* Warm
* Friendly
* Patient-safe wording

**Model:**
`mistralai/Mistral-7B-Instruct-v0.2`

---

# ğŸ§© Backend (FastAPI)

### Routes:

#### **GET /**

Returns the main chat interface.

#### **POST /api/chat**

Body:

```json
{
  "msg": "user message"
}
```

Response:

```json
{
  "response": "AI doctor's answer"
}
```

### Backend Features:

* Stores last 10 user messages
* Executes full RAG pipeline
* Async FastAPI server
* Integrates HuggingFace InferenceClient
* Clean separation between logic (`last_api.py`) and server (`main.py`)

---

# ğŸ’¬ Frontend (HTML + Jinja2)

The UI supports:

* Live message sending via Fetch API
* Automatic message display for both user and bot
* Responsive chat layout
* Easy to customize styling

Screenshot:

![UI](UI.png)

---

# ğŸš€ Installation

### 1. Clone the repository

```bash
git clone https://github.com/ahmadashrafgalal/DEPI-medical-chatbot-fastapi-frontend
cd DEPI-medical-chatbot-fastapi-frontend
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install fastapi uvicorn jinja2
pip install faiss-cpu
pip install sentence-transformers
pip install pandas numpy nltk contractions
pip install huggingface_hub
```

### 3. Run the application

```bash
python main.py
```

Server starts at:

```
http://localhost:8000
```

---

# ğŸ›  Future Enhancements

* Add user authentication
* Add streaming responses
* Add multilingual support
* Add admin dashboard
* Add chat history persistence
* Add a medical disclaimer block
* Add a model selection panel

---

# ğŸ“„ License

MIT License.

---

# ğŸ¤ Contributing

Contributions are welcome!
Feel free to open issues or submit PRs.
